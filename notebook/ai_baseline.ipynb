{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "files = sorted(glob.glob(\"../data/telemetry_run*.csv\"))\n",
    "if not files: files = [\"../data/telemetry.csv\"]   # fallback\n",
    "\n",
    "dfs = [pd.read_csv(p) for p in files]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "assert set(df.columns) == {\n",
    "    \"timestamp\",\"x\",\"y\",\"vx\",\"vy\",\"action\",\"ping_ms\",\"cheat_flag\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "\n",
    "# speed\n",
    "df[\"speed\"] = np.sqrt(df[\"vx\"]**2 + df[\"vy\"]**2)\n",
    "\n",
    "# accel from differences of velocity (Δvx, Δvy)\n",
    "df[\"ax\"] = df[\"vx\"].diff().fillna(0.0)\n",
    "df[\"ay\"] = df[\"vy\"].diff().fillna(0.0)\n",
    "df.loc[df.index[0], [\"ax\",\"ay\"]] = 0.0  # first row has no prev\n",
    "df[\"accel_mag\"] = np.sqrt(df[\"ax\"]**2 + df[\"ay\"]**2)\n",
    "\n",
    "# trailing rolling window (size=5) of speed — same as agent\n",
    "W = 5\n",
    "df[\"speed_roll_mean\"] = df[\"speed\"].rolling(W, min_periods=1).mean()\n",
    "df[\"speed_roll_std\"]  = df[\"speed\"].rolling(W, min_periods=1).std().fillna(0.0)\n",
    "\n",
    "FEATURES = [\"speed\",\"accel_mag\",\"speed_roll_mean\",\"speed_roll_std\",\"ping_ms\",\"action\"]\n",
    "X = df[FEATURES].values\n",
    "y = df[\"cheat_flag\"].values.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train counts: [218  22]\n",
      "Test  counts: [49 11]\n"
     ]
    }
   ],
   "source": [
    "# Simple blocked split: first 80% train, last 20% test\n",
    "split = int(len(df)*0.80)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Safety: ensure both classes in train\n",
    "import numpy as np\n",
    "print(\"Train counts:\", np.bincount(y_train))\n",
    "print(\"Test  counts:\", np.bincount(y_test))\n",
    "assert len(np.unique(y_train)) == 2, \"Adjust split or generate more data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_order = [\"speed\", \"accel_mag\", \"speed_roll_mean\", \"speed_roll_std\", \"ping_ms\", \"action\"]\n",
    "\n",
    "# If X is currently a NumPy array:\n",
    "X_df = pd.DataFrame(X, columns=feature_order)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_df, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "FEATURES = X_train.columns  # now this works\n",
    "\n",
    "# Train as you already do\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "scaler = logreg.named_steps[\"scaler\"]\n",
    "clf    = logreg.named_steps[\"clf\"]\n",
    "\n",
    "proba_test = logreg.predict_proba(X_test)[:,1]\n",
    "pred_test  = (proba_test >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best by F1 -> F1=1.000, P=1.000, R=1.000 at thr=0.88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "best = None\n",
    "for thr in np.linspace(0.2, 0.9, 36):\n",
    "    pred = (proba_test >= thr).astype(int)\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_test, pred, average='binary')\n",
    "    cand = (f, p, r, thr)\n",
    "    if (best is None) or (cand > best):\n",
    "        best = cand\n",
    "print(\"Best by F1 -> F1=%.3f, P=%.3f, R=%.3f at thr=%.2f\" % best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ../models/logreg_export_20251014_213425.json\n"
     ]
    }
   ],
   "source": [
    "import json, os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "scaler = logreg.named_steps[\"scaler\"]\n",
    "clf    = logreg.named_steps[\"clf\"]\n",
    "\n",
    "# 1) Normalize types to JSON-safe Python builtins\n",
    "def to_list(x):\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return list(x)\n",
    "    if isinstance(x, (np.ndarray,)):\n",
    "        return x.tolist()\n",
    "    if isinstance(x, (pd.Index, pd.Series)):\n",
    "        return x.tolist()\n",
    "    return x  # assume already a builtin\n",
    "\n",
    "FEATURES_SAFE = to_list(FEATURES)\n",
    "MEAN_SAFE     = to_list(scaler.mean_)\n",
    "SCALE_SAFE    = to_list(scaler.scale_)\n",
    "COEF_SAFE     = to_list(clf.coef_[0])\n",
    "INTERCEPT_SAFE= float(np.asarray(clf.intercept_[0]))\n",
    "\n",
    "export = {\n",
    "  \"schema_version\": 1,\n",
    "  \"type\": \"logistic_regression\",\n",
    "  \"features\": FEATURES_SAFE,             # order matters!\n",
    "  \"scaler_mean\": MEAN_SAFE,\n",
    "  \"scaler_scale\": SCALE_SAFE,\n",
    "  \"coef\": COEF_SAFE,\n",
    "  \"intercept\": INTERCEPT_SAFE,\n",
    "  \"decision_threshold\": 0.70,            # set your chosen threshold\n",
    "  \"notes\": \"trained on concatenated runs; trailing window=5; accel=diff(v)\"\n",
    "}\n",
    "\n",
    "# 2) Write with a timestamped filename\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = f\"../models/logreg_export_{ts}.json\"\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(export, f, indent=2)\n",
    "\n",
    "print(\"Wrote\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
